---
title: "Topic modeling with elife abstracts"
author: "Carson Sievert"
date: "March 31, 2014"
output: html_document
---

I recently had the pleasure of participating in [rOpenSci's hackathon](https://github.com/ropensci/hackathon/) hosted at GitHub. I've been working with [topic models](http://en.wikipedia.org/wiki/Topic_model) recently, which is a way to summarize and extract meaning from large amounts of unstructured textual data. For this reason, I was attracted to rOpenSci's [elife package](https://github.com/ropensci/elife) which makes it easy to extract [elife](http://elife.elifesciences.org/) articles via the [elife API](http://dev.elifesciences.org/). In this post, I will demonstrate how to pull every currently available elife abstract and use topic models to explore the content.

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
opts_chunk$set(eval=FALSE, message=FALSE)
```

#### Installing the package

```{r devtools}
library(devtools)
install_github("RopenSci/elife")
library(elife)
```

#### Obtain DOIs

Since we're interested in every available abstract, let's first obtain every DOI.

```{r dois}
dois <- searchelife(terms = "*", searchin = "article_title", boolean = "matches")
```

These DOIs can be used to obtain all sorts of meta data related to these articles. For our purposes, we'll just grab abstracts.

```{r abs}
abs <- NULL
for (i in 1:length(dois)) {
  ab <- elife_doi(dois[i], ret = "abstract")
  abs <- c(abs, ab)
}
```

From here, we have what we need to fit a topic model to these abstracts. I don't want to cover gorey details here, but if you're interested in how I fit this model, feel free to check out [the code](). Instead, let's jump right into exploring the topic model output.

The window below is an interactive visualization of a [Latent Dirichlet Allocation](http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) (LDA) model using elife abstracts. The aim of this visualization is to aid interpretation of topics. Topic interpretation tends to be difficult since each topic has a probability distribution over every unique word in the collection of text. With this interactive visualization, one can examine the most "relevant" words for a given topic by hovering/clicking over the appropriate circle. For an example, go ahead and click on the circle below labeled "11". 

<iframe src="coming soon" width="800" height = "1000"></iframe>

Now that topic 11 is selected, we see that "relat", "evolut", "similar", and "divert" are the top 4 most relevant words within topic 11 (in the bar chart on the right). Note that before the model was fit [stemming](http://en.wikipedia.org/wiki/Stemming) was performed. Thus, a word like "relat" could stand for "relation", "relations", "relationship", etc. You might now be asking: "That's great, I can see this topic is related to the evolution of species, but how is relevance of a word for a given topic defined?" 

To understand relevance, its helpful to know that the width of the red bars represent the frequency within topic 11 and the gray bars represent the frequency within the entire collection of text. Many people define relevance as the probability of a word given the topic (the red bars), but this tends to over-rank common words. We could also define relevance as the probability within topic divided by the overall frequency of the word (ratio of red to gray), but this tends to over-rank rare words. A sensible thing to do is to take a compromise between these two approaches. The "Value of Lambda" slider in the window above controls this compromise where a value of one ranks solely by the width of red bars and a value of zero ranks by the ratio of red to gray.

The "topic landscape" on the left-hand side gives us a sense of topic similarity by approximating distances between topics. To produce the point locations, it first computes a distance between these topic specific distributions over words, then scales the distances down to two dimensions. By default, the area of the circles are proportional to the prevalence of each topic in the collection of text. In some sense, we can verify the context of topic similarity by hovering over a word label on the bar chart which resizes circles to be proportional to the distribution over topics for that given word. For example, if we hover over "evolut" (one of the relevant words for topic 11), we see that this word is largely associated with topic 11 and 20. If we now select topic 20, it becomes immediately obvious this topic could be population genetics.

There are certainly many other interesting conclusions we can draw using this interactive visualization. I hope you take the time to explore and leave a comment with findings or questions below. If you're interested in making a similar model with different data, [rOpenSci has a bunch of R packages](http://ropensci.org/packages/index.html) that provide easy access to full text of academic articles. If you'd like to make a similar interactive visualization of your model, check out the [LDAvis](https://github.com/cpsievert/LDAvis/) package.